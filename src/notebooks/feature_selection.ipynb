{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-28T14:47:57.427837Z",
     "start_time": "2025-06-28T14:47:57.069201Z"
    }
   },
   "source": [
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from datetime import datetime\n",
    "\n",
    "from src.util.constants import DATA_PATH, FIXED_LGB_PARAMETERS\n",
    "from src.util.common import mean_grouped_spearman_correlation, save_as_pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For feature selection, we use simple correlation scoring. For hyperparameter tuning, we'll switch to performance approximation.",
   "id": "6de2b86421b3389e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T14:48:06.730933Z",
     "start_time": "2025-06-28T14:47:58.657042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train: pl.DataFrame = pl.read_parquet(f\"{DATA_PATH}/folds/df_train_0.parquet\")\n",
    "feature_names = [x for x in df_train.columns if 'feature' in x]\n",
    "del df_train\n",
    "number_of_shadow_features: int = round(len(feature_names) / 10)\n",
    "\n",
    "df_train_list = []\n",
    "df_validate_list = []\n",
    "\n",
    "def add_shadow_features(df: pl.DataFrame, _feature_names: list[str]) -> pl.DataFrame:\n",
    "    shadow_df = df.select([pl.col(col_name).shuffle().alias(f'{col_name}_shadow') for col_name in _feature_names])\n",
    "    df_with_shadow = pl.concat([df, shadow_df], how=\"horizontal\")\n",
    "\n",
    "    return df_with_shadow\n",
    "\n",
    "random_features = random.sample(feature_names, number_of_shadow_features)\n",
    "\n",
    "for fold in range(2):\n",
    "    df_train: pl.DataFrame = pl.read_parquet(f\"{DATA_PATH}/folds/df_train_{fold}.parquet\")\n",
    "    df_validate: pl.DataFrame = pl.read_parquet(f\"{DATA_PATH}/folds/df_validate_{fold}.parquet\")\n",
    "\n",
    "    df_train = add_shadow_features(df_train, random_features)\n",
    "    df_validate = add_shadow_features(df_validate, random_features)\n",
    "\n",
    "    df_train_list.append(df_train)\n",
    "    df_validate_list.append(df_validate)\n",
    "    del df_train, df_validate"
   ],
   "id": "4e09ed773c6f53d1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T15:36:27.223249Z",
     "start_time": "2025-06-28T14:48:48.302353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_list_to_test = feature_names + [f'{feature}_shadow' for feature in random_features]\n",
    "selected_features = feature_names\n",
    "\n",
    "# run on a small set of hyperparameters\n",
    "num_boost_round_space = [50, 200]\n",
    "num_leaves_space = [2**(x*2) - 1 for x in range(2, 5)]\n",
    "\n",
    "active = True\n",
    "best_mean_corr = -1.0\n",
    "best_max_corr = -1.0\n",
    "features_to_keep = feature_list_to_test\n",
    "features_to_keep_last = features_to_keep\n",
    "while active:\n",
    "    result_permutation_importance = []\n",
    "\n",
    "    corrs= []\n",
    "    for fold in range(2):\n",
    "        df_train = df_train_list[fold]\n",
    "        df_validate = df_validate_list[fold]\n",
    "\n",
    "        for num_boost_round in num_boost_round_space:\n",
    "            for num_leaves in num_leaves_space:\n",
    "                parameters = {\n",
    "                    **FIXED_LGB_PARAMETERS,\n",
    "                    'num_leaves': num_leaves,\n",
    "                    'num_boost_round': num_boost_round\n",
    "                }\n",
    "\n",
    "                # use sklearn to calculate permutation feature importances (the fastest way I found so far, faster than lleaves)\n",
    "                model = lgb.LGBMRegressor(\n",
    "                    n_estimators=num_boost_round,\n",
    "                    **parameters\n",
    "                )\n",
    "\n",
    "                # noinspection PyTypeChecker\n",
    "                model.fit(\n",
    "                    X=df_train[feature_list_to_test].to_numpy(),\n",
    "                    y=df_train['target'].to_numpy()\n",
    "                )\n",
    "\n",
    "                corr = mean_grouped_spearman_correlation(\n",
    "                    pl.Series(model.predict(df_validate[feature_list_to_test].to_numpy())),\n",
    "                    df_validate['target'],\n",
    "                    df_validate['era']\n",
    "                )\n",
    "                corrs.append(corr)\n",
    "\n",
    "\n",
    "                def mean_correlation_by_era(target: np.ndarray, prediction: np.ndarray) -> float:\n",
    "                    return mean_grouped_spearman_correlation(pl.Series(prediction), pl.Series(target), df_validate['era'])\n",
    "\n",
    "\n",
    "                score = make_scorer(mean_correlation_by_era, greater_is_better=True)\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning)  # supress false positive warning\n",
    "                result_permutation_importance.append(\n",
    "                    permutation_importance(model, df_validate[feature_list_to_test].to_numpy(), df_validate['target'].to_numpy(), scoring=score, n_repeats=1)['importances_mean']\n",
    "                )\n",
    "\n",
    "                (DATA_PATH / 'tmp').mkdir(parents=True, exist_ok=True)\n",
    "                save_as_pickle(result_permutation_importance, DATA_PATH / 'tmp/result_permutation_importance.pkl')\n",
    "\n",
    "                print(f\"{datetime.now().strftime(\"%H:%M:%S\")} . . . Fold {fold} with parameters num_boost_round={num_boost_round} and num_leaves={num_leaves} done. Current performance: {corr:.5f}.\")\n",
    "\n",
    "\n",
    "    df_feature_importance = pl.DataFrame({\n",
    "        'feature': pl.Series(feature_list_to_test),\n",
    "        'importance_permutation': pl.Series(np.array(result_permutation_importance).mean(axis=0))\n",
    "    })\n",
    "\n",
    "    max_shadow_importance = df_feature_importance.filter(pl.col('feature').str.contains('_shadow'))['importance_permutation'].max()\n",
    "\n",
    "    mean_corr = np.mean(corrs)\n",
    "    max_corr = np.max(corrs)\n",
    "    if (mean_corr + max_corr) >= (best_mean_corr + best_max_corr):\n",
    "        best_mean_corr = mean_corr\n",
    "        best_max_corr = max_corr\n",
    "    else:\n",
    "        print('No performance improvement. Stopping early and using feature set of last iteration.')\n",
    "        selected_features = [feature for feature in features_to_keep_last if 'shadow' not in feature]\n",
    "        active = False\n",
    "        break\n",
    "\n",
    "    features_to_keep_last = features_to_keep\n",
    "    features_to_keep = df_feature_importance.filter((pl.col('importance_permutation') > max_shadow_importance))['feature'].to_list()\n",
    "    features_to_keep = features_to_keep + [f'{feature}_shadow' for feature in random_features]\n",
    "\n",
    "    number_of_features_to_drop = int((len(feature_list_to_test) - len(features_to_keep)))  # excluding shadow features\n",
    "    print(f\"Dropping {number_of_features_to_drop} of {len(feature_list_to_test) - number_of_shadow_features} features\")\n",
    "\n",
    "    if number_of_features_to_drop <= 0:\n",
    "        active = False\n",
    "        print('No more features to drop. Stopping and using all surviving features.')\n",
    "        selected_features = [feature for feature in features_to_keep if 'shadow' not in feature]\n",
    "    else:\n",
    "        feature_list_to_test = features_to_keep"
   ],
   "id": "2fff67921c5a7f6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas-data-science/Library/Caches/pypoetry/virtualenvs/nmr-DUJvlELt-py3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:51:49 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.00931.\n",
      "16:54:53 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.01665.\n",
      "16:57:59 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01131.\n",
      "17:01:23 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02088.\n",
      "17:04:24 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.01144.\n",
      "17:07:29 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.02346.\n",
      "17:10:39 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01429.\n",
      "17:14:00 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02549.\n",
      "Carry on...\n",
      "Dropping 144 of 39 features\n",
      "17:14:57 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.00931.\n",
      "17:15:58 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.01695.\n",
      "17:17:00 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01131.\n",
      "17:18:09 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02123.\n",
      "17:19:14 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.01144.\n",
      "17:20:18 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.02330.\n",
      "17:21:21 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01561.\n",
      "17:22:29 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02613.\n",
      "Carry on...\n",
      "Dropping 20 of -105 features\n",
      "17:23:18 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.00921.\n",
      "17:24:08 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.01785.\n",
      "17:25:02 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01124.\n",
      "17:26:03 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02146.\n",
      "17:26:57 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.01144.\n",
      "17:27:52 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.02341.\n",
      "17:28:48 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01561.\n",
      "17:29:50 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02625.\n",
      "Carry on...\n",
      "Dropping 9 of -125 features\n",
      "17:30:36 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.00921.\n",
      "17:31:23 . . . Fold 0 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.01806.\n",
      "17:32:10 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01124.\n",
      "17:33:02 . . . Fold 0 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02206.\n",
      "17:33:49 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=3 done. Current performance: 0.01144.\n",
      "17:34:40 . . . Fold 1 with parameters num_boost_round=5 and num_leaves=15 done. Current performance: 0.02341.\n",
      "17:35:32 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=3 done. Current performance: 0.01561.\n",
      "17:36:27 . . . Fold 1 with parameters num_boost_round=15 and num_leaves=15 done. Current performance: 0.02607.\n",
      "No performance improvement. Stopping early and using feature set of last iteration.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T14:08:16.359697Z",
     "start_time": "2025-06-28T14:08:16.355939Z"
    }
   },
   "cell_type": "code",
   "source": "save_as_pickle(selected_features, DATA_PATH / 'results/selected_features.pkl')",
   "id": "1684a2e86ec5e1a0",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
